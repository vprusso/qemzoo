[
  {
    "id": "cdr",
    "name": "Clifford Data Regression",
    "abbreviation": "CDR",
    "aliases": ["variable-noise CDR", "vnCDR"],
    "category": "mitigation",
    "summary": "Trains a regression model using circuits that are close to Clifford (and thus efficiently simulable) to learn the relationship between noisy and ideal expectation values. The learned model is then applied to correct the noisy output of the target non-Clifford circuit. Because near-Clifford circuits can be simulated classically, CDR generates its own training labels without requiring a noise-free quantum device.",
    "properties": {
      "Bias": "Depends on similarity between training and target circuits",
      "Sampling overhead": "Low at inference; training requires running near-Clifford circuits",
      "Noise model required": "Implicitly learned from data; no explicit noise model needed",
      "Applicability": "General-purpose; works best when near-Clifford training circuits approximate target noise profile"
    },
    "references": ["czarnik2021", "lowe2021", "strikis2021"],
    "related": [
      {"id": "zne", "reason": "vnCDR combines CDR with variable noise scaling"},
      {"id": "ml-qem", "reason": "ML-QEM generalizes CDR's linear regression to richer ML models"}
    ]
  },
  {
    "id": "dd",
    "name": "Dynamical Decoupling",
    "abbreviation": "DD",
    "aliases": ["spin echo", "CPMG", "Uhrig dynamical decoupling", "XY-4"],
    "category": "suppression",
    "summary": "Suppresses unwanted system-environment interactions by applying sequences of fast control pulses during idle periods in a quantum circuit. The pulse sequences are designed so that the net effect of the environment averages to zero over the decoupling cycle. Common sequences include spin echo, CPMG, XY-4, and Uhrig DD, each optimized for different noise spectra.",
    "properties": {
      "Bias": "Residual errors from finite pulse width and higher-order terms",
      "Sampling overhead": "None (same number of shots); adds gate overhead",
      "Noise model required": "None, though knowledge of noise spectrum helps choose optimal sequence",
      "Applicability": "Idle qubits during circuit execution; most effective against low-frequency noise"
    },
    "references": ["viola1999", "souza2012"],
    "related": [
      {"id": "pauli-twirling", "reason": "both are suppression techniques applied at the gate level"}
    ]
  },
  {
    "id": "lre",
    "name": "Layerwise Richardson Extrapolation",
    "abbreviation": "LRE",
    "aliases": ["multivariate Richardson extrapolation"],
    "category": "mitigation",
    "summary": "Generalizes zero-noise extrapolation by scaling noise independently at each layer of a quantum circuit rather than uniformly across the entire circuit. This multivariate approach constructs a higher-dimensional extrapolation in the space of per-layer noise rates, enabling more accurate extrapolation to the zero-noise limit. The number of circuit variations scales polynomially with circuit depth \\(d\\) for a fixed extrapolation order.",
    "properties": {
      "Bias": "Reduced compared to global ZNE at the same extrapolation order",
      "Sampling overhead": "\\(\\binom{d + k - 1}{k}\\) circuit variations for depth \\(d\\) and order \\(k\\); exponential in order",
      "Noise model required": "Minimal; requires ability to scale noise at each layer independently",
      "Applicability": "Layered circuits (e.g., variational ansatze, Trotterized evolution)"
    },
    "references": ["russo2024"],
    "related": [
      {"id": "zne", "reason": "LRE is a multivariate generalization of ZNE"}
    ]
  },
  {
    "id": "measurement-error-mitigation",
    "name": "Readout Error Mitigation",
    "abbreviation": "REM",
    "aliases": ["measurement error mitigation", "MEM", "assignment matrix inversion"],
    "category": "mitigation",
    "summary": "Corrects for errors occurring during the final measurement (readout) stage of a quantum computation. The key idea is to characterize the measurement channel by preparing known computational basis states and recording the assignment probabilities, forming a confusion matrix \\(A\\). The inverse \\(A^{-1}\\) is then applied to raw measurement results to recover corrected expectation values.",
    "properties": {
      "Bias": "Zero (in principle) if the assignment matrix is exact",
      "Sampling overhead": "Grows exponentially with measurement fault rate",
      "Noise model required": "Measurement-only; characterized via \\(2^n\\) calibration circuits (or fewer with tensor product approximation)",
      "Scalability": "Full matrix inversion is \\(O(2^n)\\); tensor product or correlated subsets used in practice"
    },
    "references": ["maciejewski2020", "bravyi2021", "nation2021"],
    "related": [
      {"id": "symmetry-verification", "reason": "both can detect/correct measurement-stage errors"}
    ]
  },
  {
    "id": "n-representability",
    "name": "N-Representability Constraints",
    "abbreviation": null,
    "aliases": ["fermionic constraints", "reduced density matrix constraints"],
    "category": "mitigation",
    "note": "This is a family of constraint-based techniques rather than a single specific protocol.",
    "summary": "Leverages known constraints from quantum chemistry and many-body physics on reduced density matrices (RDMs). Physical RDMs must satisfy \\(N\\)-representability conditions (e.g., the 2-RDM must be derivable from a valid \\(N\\)-particle state). By projecting noisy estimates of RDMs onto the set of \\(N\\)-representable matrices, unphysical noise artifacts are removed.",
    "properties": {
      "Bias": "Reduced; projection removes unphysical contributions",
      "Sampling overhead": "Minimal (classical post-processing only)",
      "Noise model required": "None; uses physical constraints",
      "Applicability": "Primarily fermionic/quantum chemistry problems"
    },
    "references": ["rubin2018", "mcclean2017"],
    "related": [
      {"id": "symmetry-verification", "reason": "both exploit physical constraints to remove noise"},
      {"id": "subspace-expansion", "reason": "both are post-processing methods for variational algorithms"}
    ]
  },
  {
    "id": "pauli-twirling",
    "name": "Pauli Twirling",
    "abbreviation": "PT",
    "aliases": ["randomized compiling", "Pauli-frame randomization"],
    "category": "suppression",
    "summary": "Converts coherent (systematic) gate errors into stochastic Pauli noise by randomly conjugating each gate with Pauli operators drawn from the Pauli group, choosing pairs that preserve the gate's action up to a tracked phase. Over many randomized circuit instances, off-diagonal terms in the error channel average out, leaving a Pauli channel. This tailored noise is easier to analyze and mitigate with downstream techniques such as PEC or ZNE.",
    "properties": {
      "Bias": "Converts coherent errors to stochastic; does not remove noise on its own",
      "Sampling overhead": "Minimal; requires averaging over random Pauli insertions",
      "Noise model required": "None",
      "Applicability": "General-purpose; especially useful as a preprocessing step before PEC or ZNE"
    },
    "references": ["wallman2016", "ware2021", "hashim2021", "saki2023"],
    "related": [
      {"id": "pec", "reason": "Pauli twirling simplifies noise for PEC"},
      {"id": "zne", "reason": "Pauli twirling simplifies noise for ZNE"},
      {"id": "dd", "reason": "both are suppression techniques applied at the gate level"},
      {"id": "partial-pauli-twirling", "reason": "PPT uses a subset of Pauli gates optimized for error-detecting codes"},
      {"id": "pseudo-twirling", "reason": "pseudo twirling extends Pauli twirling to non-Clifford gates"},
      {"id": "symmetric-clifford-twirling", "reason": "SCT uses symmetric Cliffords for structure-preserving noise scrambling"}
    ]
  },
  {
    "id": "partial-pauli-twirling",
    "name": "Partial Pauli Twirling",
    "abbreviation": "PPT",
    "aliases": ["subset Pauli twirling", "optimized twirling"],
    "category": "suppression",
    "summary": "Modifies standard Pauli twirling by using only a strategically selected subset of Pauli gates rather than the full group. The subset is optimized to align errors with the detectable error space of a quantum error-detecting code, enabling synergistic combination with QED. This reduces sampling overhead and can avoid error-prone gates (e.g., Y gates on certain hardware) at the cost of incomplete noise diagonalization.",
    "properties": {
      "Bias": "Slightly higher than full twirling; does not fully diagonalize noise",
      "Sampling overhead": "Lower than full Pauli twirling; fewer circuit variants needed",
      "Noise model required": "None; optimization uses target error space from QED code",
      "Applicability": "Hybrid QED + error mitigation pipelines; hardware with biased gate errors"
    },
    "references": ["majumdar2025"],
    "related": [
      {"id": "pauli-twirling", "reason": "PPT is a resource-efficient variant of full Pauli twirling"},
      {"id": "qed", "reason": "PPT is designed to synergize with quantum error detection codes"},
      {"id": "pec", "reason": "PPT can be used as preprocessing before PEC in hybrid protocols"}
    ]
  },
  {
    "id": "pec",
    "name": "Probabilistic Error Cancellation",
    "abbreviation": "PEC",
    "aliases": ["quasi-probability decomposition", "probabilistic error correction"],
    "category": "mitigation",
    "summary": "Decomposes each ideal (noiseless) gate operation into a linear combination of noisy implementable operations with real (possibly negative) quasi-probability coefficients. By randomly sampling from this decomposition and weighting results by the sign of the coefficient, the noise-free expectation value is recovered exactly in the limit of infinite samples.",
    "properties": {
      "Bias": "Zero (unbiased estimator)",
      "Sampling overhead": "Exponential: scales as \\(\\gamma^2\\) where \\(\\gamma = \\prod_i C_i\\) is the total one-norm of the quasi-probability decomposition",
      "Noise model required": "Full characterization of local gate noise (e.g., via gate set tomography)",
      "Scalability": "Overhead grows exponentially with circuit depth and noise rate"
    },
    "references": ["temme2017", "endo2018", "vandenberg2022", "piveteau2022"],
    "related": [
      {"id": "pauli-twirling", "reason": "Pauli twirling simplifies noise model for PEC"},
      {"id": "zne", "reason": "both are foundational QEM techniques"},
      {"id": "measurement-error-mitigation", "reason": "PEC can be combined with REM for full-circuit mitigation"},
      {"id": "emre", "reason": "EMRE retains only the positive part of PEC's quasi-probability decomposition"},
      {"id": "hemre", "reason": "HEMRE interpolates between PEC and EMRE"}
    ]
  },
  {
    "id": "purification",
    "name": "Virtual Distillation",
    "abbreviation": "VD",
    "aliases": ["purification-based methods", "error suppression by derangement"],
    "category": "mitigation",
    "summary": "Exploits the fact that noise makes a pure quantum state mixed. By preparing \\(M\\) independent copies of the noisy state and measuring collective observables (e.g., via a derangement or cyclic-shift operator), the contribution of the dominant eigenvector of the density matrix is amplified exponentially in \\(M\\), effectively purifying the state.",
    "properties": {
      "Bias": "Exponentially suppressed: \\(O((\\lambda_2/\\lambda_1)^M)\\) where \\(\\lambda_1, \\lambda_2\\) are the two largest eigenvalues",
      "Sampling overhead": "Polynomial in \\(M\\); requires \\(M\\) copies of the circuit",
      "Noise model required": "None (model-free)",
      "Hardware requirements": "\\(M\\) copies of the state; entangling measurements across copies or classical shadows"
    },
    "references": ["huggins2021", "koczor2021", "cai2023"],
    "related": [
      {"id": "subspace-expansion", "reason": "both use multiple quantum states to improve estimates"},
      {"id": "symmetry-verification", "reason": "purity is itself a constraint that can be verified"},
      {"id": "logical-shadow-tomography", "reason": "virtual distillation is a special case of the LST framework"},
      {"id": "dual-state-purification", "reason": "DSP achieves similar purification without multi-copy overhead"},
      {"id": "gse", "reason": "GSE generalizes virtual distillation and QSE into a unified framework"}
    ]
  },
  {
    "id": "subspace-expansion",
    "name": "Quantum Subspace Expansion",
    "abbreviation": "QSE",
    "aliases": ["quantum subspace expansion"],
    "category": "mitigation",
    "summary": "Constructs an expanded subspace by applying a set of operators (e.g., excitation operators) to a reference state obtained from a quantum device. A generalized eigenvalue problem is then solved classically within this subspace. By including directions that span the noise-induced leakage, the method can project back onto the physical subspace and recover improved estimates.",
    "properties": {
      "Bias": "Reduced; depends on quality of subspace basis",
      "Sampling overhead": "Additional measurements for subspace matrix elements",
      "Noise model required": "None",
      "Applicability": "Primarily variational algorithms (VQE)"
    },
    "references": ["mcclean2017", "mcclean2020", "huggins2019", "yoshioka2022"],
    "related": [
      {"id": "n-representability", "reason": "both are post-processing methods for variational algorithms"},
      {"id": "purification", "reason": "both use multiple quantum states to improve estimates"},
      {"id": "symmetry-verification", "reason": "subspace expansion can incorporate symmetry constraints"},
      {"id": "qed", "reason": "QSE can decode errors similarly to quantum error detection codes"},
      {"id": "logical-shadow-tomography", "reason": "QSE is a special case of the LST framework"},
      {"id": "sqd", "reason": "SQD uses Krylov subspaces instead of excitation operators"},
      {"id": "gse", "reason": "GSE generalizes QSE to handle stochastic, coherent, and algorithmic errors"}
    ]
  },
  {
    "id": "sqd",
    "name": "Sample-Based Quantum Diagonalization",
    "abbreviation": "SQD",
    "aliases": ["sample-based Krylov diagonalization", "SKQD", "SqDRIFT"],
    "category": "mitigation",
    "summary": "Constructs a Krylov subspace by applying powers of the Hamiltonian (via time evolution) to a reference state, then uses measurement samples to build matrix representations for classical diagonalization. Unlike phase estimation, SQD avoids deep circuits by shifting computational burden to classical post-processing. The method achieves polynomial convergence guarantees while remaining practical for near-term quantum hardware.",
    "properties": {
      "Bias": "Controlled; converges to ground state with increasing Krylov dimension",
      "Sampling overhead": "Moderate; requires samples from multiple Krylov states",
      "Noise model required": "None",
      "Applicability": "Ground state estimation for many-body systems; quantum chemistry"
    },
    "references": ["yu2025", "piccinelli2025"],
    "related": [
      {"id": "subspace-expansion", "reason": "both construct subspaces for classical diagonalization; SQD uses Krylov states"},
      {"id": "zne", "reason": "SqDRIFT variant uses randomized compilation similar to noise tailoring"},
      {"id": "pauli-twirling", "reason": "SqDRIFT uses randomized Hamiltonian compilation"}
    ]
  },
  {
    "id": "symmetry-verification",
    "name": "Symmetry Verification",
    "abbreviation": "SV",
    "aliases": ["symmetry-based post-selection", "symmetry constraints"],
    "category": "mitigation",
    "summary": "Exploits known symmetries of the target quantum system (e.g., particle number conservation, parity, or spin symmetry) to detect and discard erroneous measurement outcomes. If the ideal output state is known to lie in a particular symmetry sector, any measurement result that violates this symmetry is post-selected away. A post-processing variant projects expectation values onto the symmetric subspace without discarding data.",
    "properties": {
      "Bias": "Reduced (post-selection) or adjustable (post-processing)",
      "Sampling overhead": "Inverse of pass rate (post-selection); inverse squared (post-processing)",
      "Noise model required": "None; requires knowledge of system symmetries",
      "Applicability": "Systems with known conserved quantities (chemistry, condensed matter, lattice gauge theories)"
    },
    "references": ["mcardle2019", "bonet-monroig2018", "cai2021symmetry"],
    "related": [
      {"id": "n-representability", "reason": "both exploit physical constraints"},
      {"id": "subspace-expansion", "reason": "symmetry constraints can define subspaces"},
      {"id": "measurement-error-mitigation", "reason": "both can detect measurement-stage errors"},
      {"id": "symmetry-adjusted-shadows", "reason": "SAS uses symmetry to adjust shadow inversion rather than post-select"}
    ]
  },
  {
    "id": "zne",
    "name": "Zero-Noise Extrapolation",
    "abbreviation": "ZNE",
    "aliases": ["Richardson extrapolation", "noise scaling and extrapolation"],
    "category": "mitigation",
    "summary": "Intentionally increases the noise level of a quantum circuit (e.g., by stretching pulses, inserting identity-gate pairs, or rescaling error rates) to collect expectation values at multiple noise levels. These data points are then extrapolated to the hypothetical zero-noise limit using polynomial, exponential, or other fitting models.",
    "properties": {
      "Bias": "Approximately \\(O(\\lambda^n)\\) where \\(n\\) is the number of noise levels used for extrapolation and \\(\\lambda\\) is the noise rate",
      "Sampling overhead": "Exponential in number of data points \\(M\\) (for Richardson); moderate for linear extrapolation",
      "Noise model required": "Minimal; only requires ability to scale noise controllably",
      "Scalability": "Demonstrated on up to 127 qubits; widely used in practice"
    },
    "references": ["temme2017", "li2017", "endo2018", "kim2023", "majumdar2023"],
    "related": [
      {"id": "lre", "reason": "LRE is a multivariate generalization of ZNE"},
      {"id": "pec", "reason": "both are foundational QEM techniques"},
      {"id": "pauli-twirling", "reason": "Pauli twirling simplifies noise for ZNE"},
      {"id": "cdr", "reason": "vnCDR combines CDR with noise scaling from ZNE"},
      {"id": "pie", "reason": "PIE replaces ZNE's heuristic fitting models with a physics-motivated function"}
    ]
  },
  {
    "id": "accreditation",
    "name": "Trap-Based Verification",
    "abbreviation": "TBV",
    "aliases": ["output accreditation", "accreditation protocols"],
    "category": "mitigation",
    "summary": "Certifies the output of a noisy quantum computation by interleaving 'trap' circuits — circuits whose ideal output is efficiently computable — alongside the target circuit. If the trap outputs pass verification, the target output is accredited with a certified error bound. The protocol provides a confidence interval on the distance between the noisy and ideal output distributions without requiring a noise model.",
    "properties": {
      "Bias": "None for the certification bound; target expectation value is untouched",
      "Sampling overhead": "Moderate; requires running additional trap circuits",
      "Noise model required": "None; model-free certification",
      "Applicability": "General-purpose; most useful when output correctness must be certified"
    },
    "references": ["ferracin2019"],
    "related": [
      {"id": "symmetry-verification", "reason": "both detect errors via post-selection or verification"},
      {"id": "zne", "reason": "accreditation can certify whether ZNE output is trustworthy"}
    ]
  },
  {
    "id": "qed",
    "name": "Quantum Error Detection",
    "abbreviation": "QED",
    "aliases": ["post-selective error detection", "stabilizer post-selection", "error-detecting codes"],
    "category": "mitigation",
    "summary": "Encodes logical qubits into a quantum error-detecting code (e.g., a \\([\\![ n, k, d ]\\!]\\) stabilizer code with \\(d \\geq 2\\)) and measures stabilizer generators at the end of (or during) the computation. Outcomes that flag a stabilizer violation are discarded via post-selection. Unlike full quantum error correction, QED does not attempt to correct errors — it only detects them, trading acceptance rate for output fidelity.",
    "properties": {
      "Bias": "Removed for detectable errors; undetectable errors remain",
      "Sampling overhead": "Inversely proportional to acceptance rate; depends on noise and code distance",
      "Noise model required": "None; code structure determines detectable errors",
      "Applicability": "Any circuit that can be embedded in an error-detecting code; most effective for low to moderate noise"
    },
    "references": ["knill2005", "corcoles2015", "linke2017", "mcclean2020", "urbanek2020", "gong2022", "self2024", "chertkov2025", "martiel2025", "javadi2025", "vezvaee2025", "zhang2026"],
    "related": [
      {"id": "symmetry-verification", "reason": "SV is a special case using symmetry as the detecting code"},
      {"id": "accreditation", "reason": "both use post-selection to improve output quality"},
      {"id": "partial-pauli-twirling", "reason": "PPT aligns errors with QED's detectable error space for synergistic mitigation"},
      {"id": "subspace-expansion", "reason": "QSE can function as a quantum error decoder"}
    ]
  },
  {
    "id": "trex",
    "name": "Twirled Readout Error eXtinction",
    "abbreviation": "TREX",
    "aliases": ["measurement twirling", "twirled readout mitigation"],
    "category": "mitigation",
    "summary": "Mitigates readout errors by randomly applying Pauli-X bit flips before measurement and tracking the flips classically. This twirling diagonalizes an arbitrary readout-noise channel into a single multiplicative factor per Pauli observable, which can be estimated and divided out. The method is model-free — it does not require characterizing the full assignment matrix — and avoids the exponential overhead of full matrix inversion.",
    "properties": {
      "Bias": "Zero (in principle); multiplicative correction is exact if calibration factor is accurate",
      "Sampling overhead": "Moderate; increases with readout error rate but avoids exponential matrix inversion",
      "Noise model required": "None (model-free); only requires ability to insert bit flips before measurement",
      "Applicability": "General-purpose readout error mitigation; used as resilience level 1 in Qiskit Runtime"
    },
    "references": ["vandenberg2022trex"],
    "related": [
      {"id": "measurement-error-mitigation", "reason": "both address readout errors; TREX avoids explicit confusion-matrix inversion"},
      {"id": "pauli-twirling", "reason": "both use Pauli randomization to simplify noise structure"}
    ]
  },
  {
    "id": "pea",
    "name": "Probabilistic Error Amplification",
    "abbreviation": "PEA",
    "aliases": ["learned noise amplification"],
    "category": "mitigation",
    "summary": "A noise-amplification strategy for zero-noise extrapolation that first learns the twirled noise model of each layer of entangling gates (e.g., via a sparse Pauli–Lindblad model) and then probabilistically injects single-qubit noise proportional to the learned model to achieve controlled, accurate noise scaling. Unlike pulse stretching (which assumes noise scales with gate duration) or gate folding (which requires large stretch factors), PEA provides precise amplification factors without additional calibration, making it practical for utility-scale circuits.",
    "properties": {
      "Bias": "Inherits from ZNE extrapolation model; amplification itself is accurate",
      "Sampling overhead": "Low per noise level (no exponential overhead unlike PEC); requires multiple noise levels for extrapolation",
      "Noise model required": "Learned sparse Pauli–Lindblad model of per-layer noise",
      "Applicability": "Utility-scale circuits; demonstrated on 127 qubits with 60 layers of two-qubit gates"
    },
    "references": ["kim2023", "vandenberg2023"],
    "related": [
      {"id": "zne", "reason": "PEA is a noise amplification method used within ZNE"},
      {"id": "pec", "reason": "PEA uses the same learned noise model as PEC but avoids exponential sampling overhead"},
      {"id": "pauli-twirling", "reason": "PEA operates on twirled (Pauli) noise channels"}
    ]
  },
  {
    "id": "nox",
    "name": "Noiseless Output eXtrapolation",
    "abbreviation": "NOX",
    "aliases": ["noise-learned output extrapolation"],
    "category": "mitigation",
    "summary": "Combines efficient noise reconstruction (e.g., cycle benchmarking) with noise amplification and extrapolation to the zero-noise limit. Unlike standard ZNE, which uses heuristic noise-scaling methods, NOX learns a detailed noise model per cycle of gates and uses it to perform accurate, targeted noise amplification. This allows it to handle non-local and gate-dependent noise processes that violate the assumptions of simpler extrapolation methods. The protocol was validated on superconducting processors and has been applied to quantum field theory simulations.",
    "properties": {
      "Bias": "First-order mitigation; does not cancel second-order noise terms",
      "Sampling overhead": "Moderate; noise-learning calibration plus multiple noise-scaled circuit executions",
      "Noise model required": "Learned via efficient noise reconstruction (cycle benchmarking); handles non-local and gate-dependent noise",
      "Applicability": "General-purpose; demonstrated on superconducting processors for circuits with up to ~37 hard cycles"
    },
    "references": ["ferracin2022"],
    "related": [
      {"id": "zne", "reason": "NOX is a more principled version of ZNE using a learned noise model for amplification"},
      {"id": "pec", "reason": "NOX combines noise reconstruction from PEC with extrapolation from ZNE"},
      {"id": "pea", "reason": "both use learned noise models for accurate noise amplification within ZNE"},
      {"id": "pauli-twirling", "reason": "NOX operates on twirled noise channels via randomized compiling"}
    ]
  },
  {
    "id": "echo-verification",
    "name": "Echo Verification",
    "abbreviation": "EV",
    "aliases": ["computational echo", "mirror verification"],
    "category": "mitigation",
    "summary": "Detects errors by running the target circuit forward and then its inverse (the 'echo'), so that the ideal output should return to the initial state. Deviations from the initial state signal that errors occurred. An ancilla qubit can be used to condition on successful verification, or ancilla-free variants measure the overlap directly. Echo verification effectively performs a purity-based check that amplifies the signal from the dominant eigenvector of the noisy density matrix.",
    "properties": {
      "Bias": "Reduced; errors that survive the echo are suppressed exponentially",
      "Sampling overhead": "Roughly doubles circuit depth (forward + inverse); post-selection reduces effective sample size",
      "Noise model required": "None (model-free)",
      "Applicability": "General-purpose; especially effective for coherent errors and short-to-moderate depth circuits"
    },
    "references": ["cai2021ev"],
    "related": [
      {"id": "purification", "reason": "both exploit purity to suppress noise; EV uses time-reversal instead of copies"},
      {"id": "symmetry-verification", "reason": "both use post-selection to discard erroneous runs"},
      {"id": "cdr", "reason": "EV+CDR is a powerful combined technique demonstrated in recent experiments"}
    ]
  },
  {
    "id": "tem",
    "name": "Tensor Network Error Mitigation",
    "abbreviation": "TEM",
    "aliases": ["MPO error mitigation", "matrix product operator mitigation"],
    "category": "mitigation",
    "summary": "Represents the noise channel as a matrix product operator (MPO) and applies its inverse to noisy measurement outcomes to recover mitigated expectation values. The tensor network structure captures spatially and temporally correlated noise with polynomial complexity, avoiding the exponential overhead of full process tomography. The MPO inverse is computed variationally or analytically, and the method scales to large circuits while maintaining provably optimal sampling overhead.",
    "properties": {
      "Bias": "Zero (in principle) if noise model is exact",
      "Sampling overhead": "Optimal among linear mitigation methods; polynomial in bond dimension",
      "Noise model required": "Learned MPO representation of the noise channel",
      "Applicability": "General-purpose; particularly effective for circuits with spatially correlated noise"
    },
    "references": ["guo2022", "filippov2023"],
    "related": [
      {"id": "pec", "reason": "both invert the noise channel; TEM uses tensor network structure for efficiency"},
      {"id": "nox", "reason": "both learn structured noise models; TEM uses MPO representation"}
    ]
  },
  {
    "id": "robust-shadows",
    "name": "Robust Shadow Estimation",
    "abbreviation": "RSE",
    "aliases": ["error-mitigated classical shadows", "noise-resilient shadows"],
    "category": "mitigation",
    "summary": "Extends the classical shadow estimation protocol to be robust against noise by adding a calibration stage. Instead of assuming ideal measurement channels, the protocol characterizes the noisy measurement channel and uses the calibrated inverse to construct unbiased classical shadows. This enables sample-efficient estimation of many observables simultaneously while being resilient to gate and measurement errors, with only minimal assumptions on the noise.",
    "properties": {
      "Bias": "Zero (unbiased estimator with calibrated inverse)",
      "Sampling overhead": "Same as standard shadows up to a noise-dependent multiplicative factor",
      "Noise model required": "Calibration via a small set of known input states; no explicit noise model",
      "Applicability": "Any observable estimation task; especially useful for tomographic and many-observable settings"
    },
    "references": ["chen2021"],
    "related": [
      {"id": "measurement-error-mitigation", "reason": "both calibrate the measurement channel; RSE generalizes to full shadow framework"},
      {"id": "trex", "reason": "both mitigate measurement-stage noise with calibration"},
      {"id": "logical-shadow-tomography", "reason": "both use shadow tomography; LST adds codespace projection for error mitigation"},
      {"id": "symmetry-adjusted-shadows", "reason": "both extend classical shadows; SAS uses symmetry structure instead of calibration"}
    ]
  },
  {
    "id": "symmetry-adjusted-shadows",
    "name": "Symmetry-Adjusted Classical Shadows",
    "abbreviation": "SAS",
    "aliases": ["group-theoretic error mitigation", "symmetry-adjusted shadows"],
    "category": "mitigation",
    "summary": "Adjusts classical shadow tomography based on how device errors corrupt known symmetries of the quantum system. Unlike standard symmetry verification (which post-selects), this technique uses group-theoretic structure to modify the shadow inversion itself, correcting estimates without discarding data. No calibration experiments are needed — the symmetry information alone enables error mitigation across the full circuit, not just readout errors.",
    "properties": {
      "Bias": "Reduced; uses symmetry structure to correct estimates",
      "Sampling overhead": "Low; no calibration experiments required",
      "Noise model required": "None; only requires knowledge of preserved symmetries",
      "Applicability": "Systems with known symmetries (U(1), particle number, magnetization); fermionic and spin systems"
    },
    "references": ["zhao2024"],
    "related": [
      {"id": "symmetry-verification", "reason": "both use symmetries; SV post-selects while SAS adjusts the shadow inversion"},
      {"id": "robust-shadows", "reason": "both extend classical shadows for error mitigation; RSE uses calibration, SAS uses symmetry"},
      {"id": "logical-shadow-tomography", "reason": "both use shadow tomography with additional structure for error mitigation"}
    ]
  },
  {
    "id": "logical-shadow-tomography",
    "name": "Logical Shadow Tomography",
    "abbreviation": "LST",
    "aliases": ["logical shadows", "codespace shadow tomography"],
    "category": "mitigation",
    "summary": "Performs shadow tomography on encoded logical states and uses classical post-processing to project noisy measurement data into the error-correction codespace. This filters out noise-induced errors without requiring mid-circuit syndrome measurements. LST unifies subspace expansion and virtual distillation as special cases, achieving sample complexity that scales with logical qubits \\(k\\) rather than physical qubits \\(n\\).",
    "properties": {
      "Bias": "Low; codespace projection filters detectable errors",
      "Sampling overhead": "\\(O(4^k)\\) for \\(k\\) logical qubits; much better than \\(O(2^n)\\) for subspace expansion",
      "Noise model required": "None; uses code structure",
      "Applicability": "Encoded logical qubits; efficient estimation of logical Pauli observables"
    },
    "references": ["hu2022"],
    "related": [
      {"id": "robust-shadows", "reason": "both use shadow tomography; RSE calibrates measurement noise, LST projects onto codespace"},
      {"id": "subspace-expansion", "reason": "QSE is a special case of the LST framework"},
      {"id": "purification", "reason": "virtual distillation is a special case of the LST framework"},
      {"id": "qed", "reason": "both use quantum error-detecting codes; LST applies codespace projection classically"}
    ]
  },
  {
    "id": "crosstalk-mitigation",
    "name": "Crosstalk-Adaptive Scheduling",
    "abbreviation": "CAS",
    "aliases": ["XtalkSched", "crosstalk-aware compilation"],
    "category": "suppression",
    "summary": "Suppresses crosstalk errors by intelligently scheduling gate operations to avoid simultaneous execution on qubit pairs with high crosstalk. The method first characterizes crosstalk via simultaneous randomized benchmarking, then formulates gate scheduling as an optimization problem that balances serialization (to avoid crosstalk) against parallelism (to minimize decoherence from extended circuit duration). Demonstrated up to 5.6x error reduction on 20-qubit IBM systems.",
    "properties": {
      "Bias": "Reduced; avoids crosstalk-induced coherent errors",
      "Sampling overhead": "None (same number of shots); may increase circuit duration from serialization",
      "Noise model required": "Crosstalk characterization via simultaneous randomized benchmarking",
      "Applicability": "Multi-qubit circuits on hardware with significant crosstalk (e.g., superconducting processors)"
    },
    "references": ["murali2020"],
    "related": [
      {"id": "dd", "reason": "both are suppression techniques; DD handles idle noise, CAS handles crosstalk"},
      {"id": "noise-aware-compilation", "reason": "both use hardware calibration data to improve circuit execution"}
    ]
  },
  {
    "id": "dual-state-purification",
    "name": "Dual-State Purification",
    "abbreviation": "DSP",
    "aliases": ["dual-map purification"],
    "category": "mitigation",
    "summary": "Purifies a noisy quantum state by combining it with a 'dual state' prepared by running the inverse circuit through the dual (conjugate) noise channel. The overlap between the noisy state and its dual provides an estimate equivalent to virtual distillation but without requiring multiple copies of the state or ancilla qubits. Combined with tomography purification, the method ensures the final estimate is obtained from an effectively pure state, with error reduction that improves for larger circuits.",
    "properties": {
      "Bias": "Reduced; purification suppresses off-diagonal noise contributions",
      "Sampling overhead": "Roughly doubles circuit executions (forward + dual); no qubit overhead",
      "Noise model required": "None (model-free); relies on structure of the noise channel",
      "Applicability": "Variational algorithms; demonstrated on cloud quantum computers with VQE"
    },
    "references": ["huo2022"],
    "related": [
      {"id": "purification", "reason": "both perform virtual purification; DSP avoids multi-copy overhead"},
      {"id": "echo-verification", "reason": "both use forward and inverse circuits; DSP extracts purified expectation values"}
    ]
  },
  {
    "id": "odr",
    "name": "Operator Decoherence Renormalization",
    "abbreviation": "ODR",
    "aliases": ["noise renormalization", "noise-estimation circuits"],
    "category": "mitigation",
    "summary": "Estimates the effective decoherence rate acting on a target observable by running short 'noise-estimation circuits' — circuits structurally similar to the target but with known ideal outputs. The measured decay rate is then used to renormalize (rescale) the noisy expectation value of the target observable, dividing out the noise-induced suppression factor. The method is simple, requires no detailed noise model, and is particularly effective for depolarizing-like noise.",
    "properties": {
      "Bias": "Residual bias if noise on estimation circuits differs from target circuit",
      "Sampling overhead": "Low; requires running a small number of additional calibration circuits",
      "Noise model required": "Minimal; assumes noise acts as a multiplicative suppression on observables",
      "Applicability": "Expectation value estimation; demonstrated in quantum simulation and Fourier moment computation"
    },
    "references": ["urbanek2021"],
    "related": [
      {"id": "trex", "reason": "both correct multiplicative noise factors via calibration"},
      {"id": "zne", "reason": "both address systematic noise bias; ODR uses direct rescaling instead of extrapolation"},
      {"id": "cdr", "reason": "both use classically simulable calibration circuits to learn noise effects"}
    ]
  },
  {
    "id": "nepec",
    "name": "Noise-Extended Probabilistic Error Cancellation",
    "abbreviation": "NEPEC",
    "aliases": ["noise-scaled PEC", "extended PEC"],
    "category": "mitigation",
    "summary": "Combines probabilistic error cancellation (PEC) with zero-noise extrapolation (ZNE) by extending the quasi-probability decomposition to include noise-scaled operations. Standard PEC requires expressing ideal gates as combinations of noisy implementable operations, but this decomposition may not exist or may have prohibitive overhead. NEPEC overcomes this by first scaling noise to higher levels where decompositions are possible, then extrapolating to the zero-noise limit. The framework also enables 'gate extrapolation' — performing PEC without knowing the noise model by extrapolating from multiple noise levels.",
    "properties": {
      "Bias": "Zero in principle (unbiased PEC combined with extrapolation)",
      "Sampling overhead": "Reduced compared to pure PEC; combines quasi-probability sampling with extrapolation",
      "Noise model required": "Partial or none; can use gate extrapolation to avoid explicit noise characterization",
      "Applicability": "General-purpose; especially useful when standard PEC decomposition is unavailable or expensive"
    },
    "references": ["mari2021nepec"],
    "related": [
      {"id": "pec", "reason": "NEPEC extends PEC by incorporating noise scaling"},
      {"id": "zne", "reason": "NEPEC uses extrapolation to the zero-noise limit"},
      {"id": "pea", "reason": "both combine noise scaling with other QEM techniques"}
    ]
  },
  {
    "id": "noise-aware-compilation",
    "name": "Noise-Aware Compilation",
    "abbreviation": "NAC",
    "aliases": ["noise-aware routing", "hardware-aware transpilation", "calibration-aware compilation"],
    "category": "suppression",
    "summary": "Suppresses errors at the compilation stage by using up-to-date hardware calibration data (gate error rates, coherence times, crosstalk maps) to make routing, qubit mapping, and gate scheduling decisions. This includes selecting low-error qubit subgraphs, routing SWAP operations through high-fidelity paths, and timing gate execution to avoid decoherence and crosstalk. Modern implementations recover up to 40% of missing fidelity compared to noise-unaware compilation.",
    "properties": {
      "Bias": "Reduced by avoiding high-error hardware resources",
      "Sampling overhead": "None; purely a compilation-stage optimization",
      "Noise model required": "Hardware calibration data (gate errors, T1/T2 times, crosstalk tables)",
      "Applicability": "Any quantum circuit; most impactful on hardware with non-uniform error rates"
    },
    "references": ["murali2020", "nishio2020"],
    "related": [
      {"id": "crosstalk-mitigation", "reason": "CAS is a specific form of noise-aware compilation targeting crosstalk"},
      {"id": "dd", "reason": "both are suppression techniques; NAC optimizes layout, DD optimizes idle periods"},
      {"id": "pauli-twirling", "reason": "both are preprocessing steps that improve downstream mitigation"}
    ]
  },
  {
    "id": "emre",
    "name": "Error Mitigation by Restricted Evolution",
    "abbreviation": "EMRE",
    "aliases": ["restricted evolution mitigation"],
    "category": "mitigation",
    "summary": "Trades unbiasedness for constant sampling overhead by retaining only the positive (implementable) part of the quasi-probability decomposition used in PEC. For each ideal gate, EMRE finds the closest implementable operation in the semidefinite ordering sense and a scaling factor (the generalized robustness \\(R^+\\)) that quantifies the distance. The resulting estimator has finite bias that depends on the generalized robustness, but its sample complexity is constant — independent of noise rate and circuit depth.",
    "properties": {
      "Bias": "Finite; bounded by \\(s - 1\\) where \\(s = \\prod_i (1 + R^+_i)\\) grows with circuit depth",
      "Sampling overhead": "Constant: \\(M = \\frac{2}{c^2} \\ln(2/p_{\\text{fail}})\\), independent of noise and depth",
      "Noise model required": "Full characterization of gate noise to compute the generalized quasi-probability decomposition",
      "Applicability": "High-fidelity hardware (gate fidelity ≥ 99.7%); shallow-to-moderate depth circuits"
    },
    "references": ["saxena2024"],
    "related": [
      {"id": "pec", "reason": "EMRE uses the same quasi-probability framework as PEC but discards the negative correction terms"},
      {"id": "hemre", "reason": "HEMRE is a hybrid protocol interpolating between EMRE and PEC"},
      {"id": "pie", "reason": "PIE derives its extrapolation model from EMRE's theoretical framework"},
      {"id": "zne", "reason": "EMRE avoids the heuristic extrapolation model assumptions of ZNE"}
    ]
  },
  {
    "id": "hemre",
    "name": "Hybrid Error Mitigation by Restricted Evolution",
    "abbreviation": "HEMRE",
    "aliases": ["hybrid EMRE"],
    "category": "mitigation",
    "summary": "Interpolates continuously between PEC and EMRE by introducing an adjustable bias tolerance parameter \\(\\Delta_{\\text{fixed}}\\). Gates whose generalized robustness is below the threshold receive the EMRE approximation (biased but cheap), while remaining gates receive full PEC treatment (unbiased but expensive). At \\(\\Delta_{\\text{fixed}} = 0\\) HEMRE reduces to PEC; as \\(\\Delta_{\\text{fixed}} \\to \\infty\\) it reduces to EMRE.",
    "properties": {
      "Bias": "Tunable; bounded by user-specified \\(\\Delta_{\\text{fixed}}\\)",
      "Sampling overhead": "Intermediate between PEC (exponential) and EMRE (constant); depends on gate partition",
      "Noise model required": "Full characterization of gate noise for both EMRE and PEC decompositions",
      "Applicability": "Moderate-noise regimes (0.1%–1% error rates) where neither pure EMRE nor pure PEC is optimal"
    },
    "references": ["saxena2024"],
    "related": [
      {"id": "pec", "reason": "HEMRE reduces to PEC when the bias tolerance is zero"},
      {"id": "emre", "reason": "HEMRE reduces to EMRE when the bias tolerance is unlimited"},
      {"id": "pie", "reason": "both build on the EMRE theoretical framework"},
      {"id": "zne", "reason": "HEMRE avoids model-dependent extrapolation"}
    ]
  },
  {
    "id": "kik",
    "name": "K-Inverse-K (KIK)",
    "abbreviation": null,
    "aliases": ["adaptive KIK", "pulse-based inverse evolution", "layered KIK"],
    "category": "mitigation",
    "summary": "Mitigates errors by combining noisy circuit outputs with outputs from pulse-based inverse evolutions, using adaptive coefficients tuned to the device noise level. Unlike gate-level folding (ZNE) or echo verification, KIK constructs the inverse at the pulse level by reversing pulse amplitudes and time ordering, enabling more accurate noise cancellation. The method adapts to moderate-to-strong noise regimes and integrates with randomized compiling to handle both coherent and incoherent noise.",
    "properties": {
      "Bias": "Low; first-order noise cancellation with adaptive coefficients",
      "Sampling overhead": "Low; number of circuits is independent of system size",
      "Noise model required": "None; no tomography or machine learning required",
      "Applicability": "General-purpose; handles moderate-to-strong noise, time-dependent noise, and spatially correlated errors"
    },
    "references": ["botelho2023", "botelho2025"],
    "related": [
      {"id": "echo-verification", "reason": "both use forward and inverse circuits; KIK operates at pulse level with adaptive coefficients"},
      {"id": "zne", "reason": "KIK outperforms circuit folding ZNE by using pulse-based inverses and adaptive coefficients"},
      {"id": "pauli-twirling", "reason": "KIK integrates with randomized compiling to handle coherent noise"},
      {"id": "dd", "reason": "both operate at the pulse level to suppress noise"}
    ]
  },
  {
    "id": "pie",
    "name": "Physics-Inspired Extrapolation",
    "abbreviation": "PIE",
    "aliases": ["physics-inspired ZNE"],
    "category": "mitigation",
    "summary": "Performs zero-noise extrapolation using a theoretically motivated fitting function derived from the EMRE framework rather than heuristic polynomial or exponential models. The model \\(f(\\lambda) = \\langle O \\rangle_{\\text{ideal}} \\cdot s^{-\\lambda}\\) linearizes in log-space, where the intercept gives the ideal expectation value and the slope equals the max-relative entropy between ideal and noisy circuits. This provides simultaneous error mitigation and hardware certification at no additional cost. Demonstrated on 84-qubit IBM Eagle processor.",
    "properties": {
      "Bias": "Low; converges to zero as noise decreases. Comes from neglecting the GQPD correction term",
      "Sampling overhead": "Linear (~4× base circuit execution); typically requires only 4 noise-scaled data points",
      "Noise model required": "None; noise-agnostic like standard ZNE",
      "Applicability": "Shallow-to-moderate depth circuits; demonstrated at scale (84 qubits)"
    },
    "references": ["diezvalle2025", "saxena2024"],
    "related": [
      {"id": "zne", "reason": "PIE uses the same circuit folding as ZNE but with a physics-motivated fitting function"},
      {"id": "emre", "reason": "PIE's fitting function is derived from EMRE's generalized quasi-probability decomposition"},
      {"id": "hemre", "reason": "both build on the EMRE theoretical framework"},
      {"id": "lre", "reason": "both are extrapolation-based methods; PIE uses a single global physics-motivated model"}
    ]
  },
  {
    "id": "ml-qem",
    "name": "Machine Learning QEM",
    "abbreviation": "ML-QEM",
    "aliases": ["neural error mitigation", "NEM", "learning-based QEM", "data-driven error mitigation"],
    "category": "mitigation",
    "summary": "Uses classical machine learning models — including linear regression, random forests, multi-layer perceptrons, and graph neural networks — to learn the mapping from noisy to ideal expectation values. Training data is generated from near-Clifford circuits (efficiently simulable) or circuits at multiple noise levels. ML-QEM dramatically reduces the runtime overhead of traditional QEM methods (2× or more reduction) without sacrificing accuracy, and has been demonstrated on quantum hardware with up to 100 qubits.",
    "properties": {
      "Bias": "Depends on model generalization; zero if training distribution matches target",
      "Sampling overhead": "Low at inference; training requires running calibration circuits",
      "Noise model required": "Implicitly learned from data; no explicit noise characterization needed",
      "Applicability": "General-purpose; best when training circuits approximate target circuit structure"
    },
    "references": ["liao2024", "czarnik2022nem", "kim2023nem", "strikis2021"],
    "related": [
      {"id": "cdr", "reason": "CDR uses linear regression on near-Clifford training data; ML-QEM generalizes to richer models"},
      {"id": "zne", "reason": "ML-QEM can replace ZNE's extrapolation with learned models, reducing overhead"},
      {"id": "pec", "reason": "ML-QEM achieves similar accuracy to PEC with dramatically lower sampling cost"}
    ]
  },
  {
    "id": "gse",
    "name": "Generalized Subspace Expansion",
    "abbreviation": "GSE",
    "aliases": ["generalized quantum subspace expansion", "power subspace method"],
    "category": "mitigation",
    "summary": "A unified error mitigation framework that handles stochastic, coherent, and algorithmic errors simultaneously by constructing an expanded subspace from powers of the noisy density matrix (\\(\\rho^m\\)) or error-boosted states. GSE generalizes both quantum subspace expansion and virtual distillation, inheriting advantages of both while overcoming their individual limitations. The method is noise-agnostic and can suppress errors by orders of magnitude without requiring knowledge of the noise model.",
    "properties": {
      "Bias": "Suppressed exponentially with subspace dimension",
      "Sampling overhead": "Moderate; requires measuring matrix elements in expanded subspace",
      "Noise model required": "None (noise-agnostic)",
      "Applicability": "General-purpose; particularly effective for variational algorithms and Hamiltonian simulation"
    },
    "references": ["yoshioka2022"],
    "related": [
      {"id": "subspace-expansion", "reason": "QSE is a special case of GSE"},
      {"id": "purification", "reason": "virtual distillation is a special case of GSE"},
      {"id": "dual-state-purification", "reason": "Dual-GSE combines GSE with dual-state purification for resource efficiency"},
      {"id": "logical-shadow-tomography", "reason": "both provide unified frameworks for multiple QEM techniques"}
    ]
  },
  {
    "id": "pseudo-twirling",
    "name": "Pseudo Twirling",
    "abbreviation": "PT",
    "aliases": ["pseudo-Pauli twirling", "non-Clifford twirling"],
    "category": "suppression",
    "summary": "Extends Pauli twirling to mitigate coherent errors in non-Clifford gates, where standard twirling fails. For gates like partial CPhase rotations (small-angle ZZ interactions), pseudo twirling applies approximate twirling operations that convert coherent errors into quasi-stochastic noise while preserving the gate's action. Can be combined with Adaptive KIK to simultaneously address both coherent and incoherent errors. Experimentally validated on native gate implementations.",
    "properties": {
      "Bias": "Small residual from imperfect twirling of non-Clifford gates",
      "Sampling overhead": "Similar to Pauli twirling; requires averaging over randomized circuits",
      "Noise model required": "None",
      "Applicability": "Non-Clifford gates (partial rotations, native entangling gates); addresses calibration imperfections and crosstalk"
    },
    "references": ["santos2024"],
    "related": [
      {"id": "pauli-twirling", "reason": "pseudo twirling extends Pauli twirling to non-Clifford gates"},
      {"id": "kik", "reason": "can be combined with KIK to address both coherent and incoherent errors"},
      {"id": "symmetric-clifford-twirling", "reason": "both extend standard twirling to broader gate classes"}
    ]
  },
  {
    "id": "symmetric-clifford-twirling",
    "name": "Symmetric Clifford Twirling",
    "abbreviation": "SCT",
    "aliases": ["symmetric twirling", "structure-preserving twirling"],
    "category": "suppression",
    "summary": "Applies Clifford twirling using only symmetric Clifford operators that commute with certain Pauli subgroups, preserving the structure of the target operation while scrambling noise to approximately global white noise with exponential precision. Hardware-efficient variants use only local symmetric Cliffords to accelerate noise scrambling. Particularly effective in the early fault-tolerant regime where non-Clifford operations must be error-mitigated with minimal overhead.",
    "properties": {
      "Bias": "Exponentially small; noise approaches global white noise",
      "Sampling overhead": "Reduced compared to full Clifford twirling; hardware-efficient variants minimize gate count",
      "Noise model required": "None",
      "Applicability": "Early FTQC regime; Hamiltonian simulation; circuits with non-Clifford operations"
    },
    "references": ["tsubouchi2025"],
    "related": [
      {"id": "pauli-twirling", "reason": "symmetric Clifford twirling is a structured extension of Pauli twirling"},
      {"id": "pseudo-twirling", "reason": "both extend twirling techniques beyond standard Pauli/Clifford gates"},
      {"id": "pec", "reason": "can be used as preprocessing to simplify noise for PEC"}
    ]
  }
]
